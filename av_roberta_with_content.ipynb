{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1A6XJdN97HG4RZBULl98qz7GzNRcsgNZI","timestamp":1683433929000},{"file_id":"1saviTKwy4DP0BLE1p1KoL7hTcYdX8QRh","timestamp":1683256114850}],"mount_file_id":"1oVbRYMuYk2Yz7CrFrkXozk_Wt4CFnhQo","authorship_tag":"ABX9TyMHKWf7bSxJNi9TzFgLnQeu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y8EkIjvqKMbw","executionInfo":{"status":"ok","timestamp":1683697197442,"user_tz":300,"elapsed":22978,"user":{"displayName":"Venkata Sai Krishna Abbaraju","userId":"03956108207244612420"}},"outputId":"57f46ad9-e3d2-45ab-b3d8-85d3a41f4d88"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.11.0 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"]}],"source":["!pip install transformers\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import transformers\n","import torch\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","source":["df = pd.read_csv(\"/content/drive/MyDrive/pro/8701/combined_14510_xlnet.csv\")\n","df.head()\n","title_content = df[(df['title_polyglot_detect'] == 'en') & (df['title_lang_detect'] == 'en') & (df['title_langid_detect'] == 'en') & (df['title_xl_detect'] == 'en') & (df['content_polyglot_detect'] == 'en') & (df['content_lang_detect'] == 'en') & (df['content_langid_detect'] == 'en') & (df['content_xl_detect'] == 'en')][['question_title', 'question_content', 'class_index']]\n","# title_content.shape\n","title_content['title_content'] = title_content['question_title'] + \" \" +title_content['question_content']"],"metadata":{"id":"Pofp17ngKa4d","executionInfo":{"status":"ok","timestamp":1683697198300,"user_tz":300,"elapsed":862,"user":{"displayName":"Venkata Sai Krishna Abbaraju","userId":"03956108207244612420"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import transformers\n","from transformers import RobertaModel, RobertaTokenizer\n","\n","# specify GPU\n","from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'"],"metadata":{"id":"NllVI1asKsKB","executionInfo":{"status":"ok","timestamp":1683697199719,"user_tz":300,"elapsed":1422,"user":{"displayName":"Venkata Sai Krishna Abbaraju","userId":"03956108207244612420"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n","label2id = {\n","    1: 0,\n","    5: 1,\n","    6: 2,\n","    10: 3\n","}\n","\n","id2label = {\n","    0: 1,\n","    1: 5,\n","    2: 6,\n","    3: 10\n","}\n","class Dataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, df):\n","\n","        self.labels = [label2id[label] for label in df['class_index']]\n","        self.texts = [tokenizer(text, \n","                               padding='max_length', max_length = 512, truncation=True,\n","                                return_tensors=\"pt\") for text in df['title_content']]\n","\n","    def classes(self):\n","        return self.labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def get_batch_labels(self, idx):\n","        # Fetch a batch of labels\n","        return np.array(self.labels[idx])\n","\n","    def get_batch_texts(self, idx):\n","        # Fetch a batch of inputs\n","        return self.texts[idx]\n","\n","    def __getitem__(self, idx):\n","\n","        batch_texts = self.get_batch_texts(idx)\n","        batch_y = self.get_batch_labels(idx)\n","\n","        return batch_texts, batch_y"],"metadata":{"id":"JTP1tiyKmehl","executionInfo":{"status":"ok","timestamp":1683698401734,"user_tz":300,"elapsed":1845,"user":{"displayName":"Venkata Sai Krishna Abbaraju","userId":"03956108207244612420"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["np.random.seed(112)\n","df_train, df_val, df_test = np.split(title_content.sample(frac=1, random_state=42), \n","                                     [int(.8*len(title_content)), int(.9*len(title_content))])\n","\n","print(len(df_train),len(df_val), len(df_test)) #dataframes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3liry60Bmedj","executionInfo":{"status":"ok","timestamp":1683698405697,"user_tz":300,"elapsed":8,"user":{"displayName":"Venkata Sai Krishna Abbaraju","userId":"03956108207244612420"}},"outputId":"a640012b-8cc9-4cf9-dc27-c9b6c89b8f69"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["12026 1503 1504\n"]}]},{"cell_type":"code","source":["from torch import nn\n","\n","class RoBertaClassifier(nn.Module):\n","\n","    def __init__(self): #, dropout=0.5\n","\n","        super(RoBertaClassifier, self).__init__()\n","\n","        self.roberta = AutoModelForSequenceClassification.from_pretrained('roberta-base', num_labels = 4, label2id=label2id, id2label=id2label)\n","        # self.dropout = nn.Dropout(dropout)\n","        # self.linear = nn.Linear(768, 4)\n","        # self.relu = nn.ReLU()\n","\n","    def forward(self, input_id, mask):\n","\n","        pooled_output = self.roberta(input_ids= input_id, attention_mask=mask,return_dict=False)\n","    #     dropout_output = self.dropout(pooled_output)\n","    #     linear_output = self.linear(dropout_output)\n","    #     final_layer = self.relu(linear_output)\n","        # print(pooled_output)\n","        # print(pooled_output.shape)\n","        # print(pooled_output[0])\n","\n","        return pooled_output\n","\n","    def save_model(self, path, tokenizer): #'/content/drive/MyDrive/pro/8701/roberta_model_content/'\n","        self.roberta.save_pretrained(path)\n","        tokenizer.save_pretrained(path)"],"metadata":{"id":"5SBgOaUFmecp","executionInfo":{"status":"ok","timestamp":1683698408375,"user_tz":300,"elapsed":4,"user":{"displayName":"Venkata Sai Krishna Abbaraju","userId":"03956108207244612420"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from torch.optim import Adam\n","from tqdm import tqdm\n","\n","def train(model, train_data, val_data, learning_rate, epochs):\n","\n","    train, val = Dataset(train_data), Dataset(val_data)\n","\n","    train_dataloader = torch.utils.data.DataLoader(train, batch_size=8, shuffle=True)\n","    val_dataloader = torch.utils.data.DataLoader(val, batch_size=8)\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = Adam(model.parameters(), lr= learning_rate)\n","\n","    train_acc = []\n","    valid_acc = []\n","\n","    if use_cuda:\n","\n","            model = model.cuda()\n","            criterion = criterion.cuda()\n","\n","    for epoch_num in range(epochs):\n","\n","            total_acc_train = 0\n","            total_loss_train = 0\n","\n","            for train_input, train_label in tqdm(train_dataloader):\n","\n","                train_label = train_label.to(device)\n","                mask = train_input['attention_mask'].to(device)\n","                input_id = train_input['input_ids'].squeeze(1).to(device)\n","\n","                output = model(input_id, mask)\n","                \n","                batch_loss = criterion(output[0], train_label.long())\n","                total_loss_train += batch_loss.item()\n","                \n","                acc = (output[0].argmax(dim=1) == train_label).sum().item()\n","                total_acc_train += acc\n","\n","                model.zero_grad()\n","                batch_loss.backward()\n","                optimizer.step()\n","            \n","            total_acc_val = 0\n","            total_loss_val = 0\n","\n","            with torch.no_grad():\n","\n","                for val_input, val_label in val_dataloader:\n","\n","                    val_label = val_label.to(device)\n","                    mask = val_input['attention_mask'].to(device)\n","                    input_id = val_input['input_ids'].squeeze(1).to(device)\n","\n","                    output = model(input_id, mask)\n","\n","                    batch_loss = criterion(output[0], val_label.long())\n","                    total_loss_val += batch_loss.item()\n","                    \n","                    acc = (output[0].argmax(dim=1) == val_label).sum().item()\n","                    total_acc_val += acc\n","            \n","            print(\n","                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n","                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n","                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n","                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n","            \n","            train_acc.append(total_acc_train / len(train_data))\n","            valid_acc.append(total_acc_val / len(val_data))\n","            \n","            path = '/content/drive/MyDrive/pro/8701/roberta_model_content/saved_weights_' + str(epoch_num)\n","            print(path)\n","            # torch.save(model.state_dict(), path)\n","            model.save_model(path = path, tokenizer=tokenizer)\n","\n","            \n","    return train_acc, valid_acc\n","                  \n","EPOCHS = 3\n","model = RoBertaClassifier()\n","LR = 1e-5\n","\n","train(model, df_train, df_val, LR, EPOCHS)\n","# train(model, df_train.iloc[:10], df_val.iloc[:8], LR, EPOCHS)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1hJYylPboOTv","executionInfo":{"status":"ok","timestamp":1683701526702,"user_tz":300,"elapsed":3115463,"user":{"displayName":"Venkata Sai Krishna Abbaraju","userId":"03956108207244612420"}},"outputId":"4e4171c0-6c8f-4854-d7ab-deadf0a6fb63"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100%|██████████| 1504/1504 [16:31<00:00,  1.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.041                 | Train Accuracy:  0.889                 | Val Loss:  0.032                 | Val Accuracy:  0.912\n","/content/drive/MyDrive/pro/8701/roberta_model_content/saved_weights_0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1504/1504 [16:31<00:00,  1.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.020                 | Train Accuracy:  0.950                 | Val Loss:  0.032                 | Val Accuracy:  0.913\n","/content/drive/MyDrive/pro/8701/roberta_model_content/saved_weights_1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1504/1504 [16:30<00:00,  1.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.010                 | Train Accuracy:  0.976                 | Val Loss:  0.039                 | Val Accuracy:  0.908\n","/content/drive/MyDrive/pro/8701/roberta_model_content/saved_weights_2\n"]},{"output_type":"execute_result","data":{"text/plain":["([0.8890736737069682, 0.9496091801097621, 0.9763845002494596],\n"," [0.9115103127079175, 0.9128409846972722, 0.908183632734531])"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["Run Till the above step. \n","Share the notebook, model weights that are saved and optimal parameters like epochs, LR. The notebook should have training and  validation error details."],"metadata":{"id":"K3fQtZp2flqk"}},{"cell_type":"code","source":[],"metadata":{"id":"JRVvsoz4cF3S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, test_data):\n","\n","    test = Dataset(test_data)\n","    pred_label = []\n","    test_dataloader = torch.utils.data.DataLoader(test, batch_size=8)\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    if use_cuda:\n","\n","        model = model.cuda()\n","\n","    total_acc_test = 0\n","    with torch.no_grad():\n","\n","        for test_input, test_label in test_dataloader:\n","\n","              test_label = test_label.to(device)\n","              mask = test_input['attention_mask'].to(device)\n","              input_id = test_input['input_ids'].squeeze(1).to(device)\n","\n","              output = model(input_id, mask)\n","              pred = output[0].argmax(dim=1)\n","              # print(pred)\n","              # print(test_label)\n","              pred_label.append(pred)\n","              acc = (output[0].argmax(dim=1) == test_label).sum().item()\n","              total_acc_test += acc\n","    \n","    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n","    return pred_label\n","\n","#load weights of best model\n","model2 = AutoModelForSequenceClassification.from_pretrained('/content/drive/MyDrive/pro/8701/roberta_model_content/saved_weights_1')\n","tokenizer2 = AutoTokenizer.from_pretrained('/content/drive/MyDrive/pro/8701/roberta_model_content/saved_weights_1')\n","\n","# #load weights of best model\n","# model_test = RoBertaClassifier()\n","# path = '/content/drive/MyDrive/pro/8701/roberta_model/saved_weights_0.pt'\n","# model_test.load_state_dict(torch.load(path))\n","\n","evaluate(model2, df_test)\n","# evaluate(model_test, df_train.iloc[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gDlWSuRBoeuO","executionInfo":{"status":"ok","timestamp":1683701602147,"user_tz":300,"elapsed":50102,"user":{"displayName":"Venkata Sai Krishna Abbaraju","userId":"03956108207244612420"}},"outputId":"08271c8b-c7cb-4387-9013-f89a6986e9fe"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy:  0.915\n"]},{"output_type":"execute_result","data":{"text/plain":["[tensor([0, 2, 2, 0, 2, 2, 3, 2], device='cuda:0'),\n"," tensor([2, 3, 0, 3, 1, 2, 0, 1], device='cuda:0'),\n"," tensor([0, 1, 2, 0, 0, 1, 1, 2], device='cuda:0'),\n"," tensor([3, 3, 0, 1, 1, 3, 2, 3], device='cuda:0'),\n"," tensor([3, 3, 3, 3, 2, 2, 0, 0], device='cuda:0'),\n"," tensor([1, 0, 0, 0, 2, 1, 0, 0], device='cuda:0'),\n"," tensor([0, 1, 2, 3, 3, 0, 3, 2], device='cuda:0'),\n"," tensor([1, 1, 2, 2, 3, 3, 1, 2], device='cuda:0'),\n"," tensor([3, 2, 1, 3, 1, 3, 0, 1], device='cuda:0'),\n"," tensor([1, 3, 1, 2, 0, 1, 1, 0], device='cuda:0'),\n"," tensor([0, 3, 2, 1, 2, 2, 3, 2], device='cuda:0'),\n"," tensor([3, 0, 1, 0, 2, 3, 0, 0], device='cuda:0'),\n"," tensor([3, 0, 0, 0, 1, 2, 0, 3], device='cuda:0'),\n"," tensor([3, 2, 2, 3, 3, 1, 2, 1], device='cuda:0'),\n"," tensor([0, 3, 2, 0, 0, 3, 0, 1], device='cuda:0'),\n"," tensor([1, 0, 1, 0, 3, 0, 1, 1], device='cuda:0'),\n"," tensor([1, 3, 3, 1, 3, 3, 1, 0], device='cuda:0'),\n"," tensor([1, 3, 0, 0, 1, 3, 1, 0], device='cuda:0'),\n"," tensor([2, 0, 3, 2, 1, 2, 0, 0], device='cuda:0'),\n"," tensor([1, 0, 3, 3, 3, 3, 3, 2], device='cuda:0'),\n"," tensor([3, 2, 2, 1, 1, 1, 1, 3], device='cuda:0'),\n"," tensor([0, 0, 2, 1, 3, 0, 3, 0], device='cuda:0'),\n"," tensor([3, 1, 2, 3, 1, 1, 2, 1], device='cuda:0'),\n"," tensor([3, 3, 2, 1, 0, 3, 0, 2], device='cuda:0'),\n"," tensor([1, 0, 3, 3, 1, 1, 2, 2], device='cuda:0'),\n"," tensor([0, 2, 2, 1, 1, 2, 0, 2], device='cuda:0'),\n"," tensor([1, 0, 0, 2, 1, 0, 1, 1], device='cuda:0'),\n"," tensor([0, 3, 0, 2, 0, 1, 3, 0], device='cuda:0'),\n"," tensor([2, 1, 2, 1, 0, 0, 3, 3], device='cuda:0'),\n"," tensor([0, 0, 1, 2, 2, 3, 2, 2], device='cuda:0'),\n"," tensor([2, 3, 2, 0, 1, 1, 1, 2], device='cuda:0'),\n"," tensor([3, 2, 2, 2, 1, 0, 1, 3], device='cuda:0'),\n"," tensor([2, 0, 1, 0, 1, 3, 1, 1], device='cuda:0'),\n"," tensor([1, 3, 0, 3, 1, 1, 3, 0], device='cuda:0'),\n"," tensor([0, 3, 2, 1, 1, 0, 1, 0], device='cuda:0'),\n"," tensor([3, 1, 1, 3, 3, 0, 3, 1], device='cuda:0'),\n"," tensor([2, 2, 1, 2, 0, 2, 1, 1], device='cuda:0'),\n"," tensor([2, 0, 2, 0, 2, 2, 0, 3], device='cuda:0'),\n"," tensor([3, 2, 1, 3, 1, 3, 3, 1], device='cuda:0'),\n"," tensor([1, 1, 0, 1, 3, 1, 3, 1], device='cuda:0'),\n"," tensor([0, 3, 3, 0, 3, 3, 2, 0], device='cuda:0'),\n"," tensor([0, 2, 2, 1, 2, 3, 1, 2], device='cuda:0'),\n"," tensor([0, 2, 2, 2, 0, 0, 1, 0], device='cuda:0'),\n"," tensor([2, 3, 0, 3, 0, 1, 3, 3], device='cuda:0'),\n"," tensor([2, 3, 3, 3, 1, 0, 1, 2], device='cuda:0'),\n"," tensor([2, 1, 2, 0, 0, 0, 1, 3], device='cuda:0'),\n"," tensor([0, 2, 1, 2, 2, 3, 0, 3], device='cuda:0'),\n"," tensor([0, 2, 3, 2, 1, 1, 3, 2], device='cuda:0'),\n"," tensor([1, 3, 3, 2, 2, 1, 0, 1], device='cuda:0'),\n"," tensor([0, 0, 3, 3, 2, 3, 3, 2], device='cuda:0'),\n"," tensor([2, 3, 2, 1, 3, 1, 3, 2], device='cuda:0'),\n"," tensor([1, 0, 3, 0, 0, 0, 1, 1], device='cuda:0'),\n"," tensor([1, 1, 2, 1, 3, 3, 2, 3], device='cuda:0'),\n"," tensor([0, 3, 3, 0, 3, 0, 2, 2], device='cuda:0'),\n"," tensor([2, 0, 0, 3, 3, 1, 1, 3], device='cuda:0'),\n"," tensor([1, 3, 0, 0, 3, 0, 3, 0], device='cuda:0'),\n"," tensor([3, 3, 0, 1, 3, 0, 3, 3], device='cuda:0'),\n"," tensor([3, 2, 3, 0, 2, 0, 1, 2], device='cuda:0'),\n"," tensor([1, 3, 1, 3, 1, 3, 1, 2], device='cuda:0'),\n"," tensor([3, 2, 1, 3, 1, 3, 2, 3], device='cuda:0'),\n"," tensor([3, 1, 0, 3, 3, 3, 1, 0], device='cuda:0'),\n"," tensor([3, 1, 1, 1, 0, 1, 3, 2], device='cuda:0'),\n"," tensor([0, 1, 2, 1, 0, 1, 3, 0], device='cuda:0'),\n"," tensor([1, 1, 2, 0, 3, 3, 1, 0], device='cuda:0'),\n"," tensor([2, 2, 1, 3, 3, 3, 2, 3], device='cuda:0'),\n"," tensor([3, 1, 2, 3, 3, 0, 3, 1], device='cuda:0'),\n"," tensor([1, 0, 2, 2, 1, 3, 0, 2], device='cuda:0'),\n"," tensor([2, 1, 0, 2, 2, 3, 2, 0], device='cuda:0'),\n"," tensor([3, 2, 3, 3, 2, 2, 1, 2], device='cuda:0'),\n"," tensor([1, 2, 1, 0, 0, 2, 3, 3], device='cuda:0'),\n"," tensor([1, 0, 0, 1, 0, 3, 0, 3], device='cuda:0'),\n"," tensor([3, 2, 0, 3, 2, 1, 0, 0], device='cuda:0'),\n"," tensor([1, 3, 3, 2, 0, 3, 3, 3], device='cuda:0'),\n"," tensor([0, 3, 2, 3, 1, 0, 3, 3], device='cuda:0'),\n"," tensor([0, 2, 3, 2, 1, 2, 3, 0], device='cuda:0'),\n"," tensor([3, 1, 1, 3, 1, 1, 0, 2], device='cuda:0'),\n"," tensor([3, 2, 1, 0, 3, 1, 2, 1], device='cuda:0'),\n"," tensor([0, 2, 2, 3, 1, 0, 1, 2], device='cuda:0'),\n"," tensor([2, 2, 1, 2, 3, 1, 3, 1], device='cuda:0'),\n"," tensor([1, 3, 2, 3, 0, 3, 2, 2], device='cuda:0'),\n"," tensor([3, 3, 2, 3, 0, 0, 3, 2], device='cuda:0'),\n"," tensor([0, 0, 0, 2, 1, 2, 0, 1], device='cuda:0'),\n"," tensor([1, 3, 2, 1, 3, 2, 1, 0], device='cuda:0'),\n"," tensor([2, 3, 3, 3, 2, 2, 2, 2], device='cuda:0'),\n"," tensor([1, 3, 1, 3, 0, 3, 0, 0], device='cuda:0'),\n"," tensor([3, 0, 1, 1, 0, 3, 3, 1], device='cuda:0'),\n"," tensor([1, 1, 2, 1, 1, 2, 0, 1], device='cuda:0'),\n"," tensor([3, 1, 3, 0, 1, 0, 2, 1], device='cuda:0'),\n"," tensor([2, 3, 0, 2, 0, 0, 1, 1], device='cuda:0'),\n"," tensor([3, 0, 0, 3, 3, 0, 3, 1], device='cuda:0'),\n"," tensor([0, 1, 3, 3, 1, 3, 1, 3], device='cuda:0'),\n"," tensor([1, 3, 3, 3, 0, 0, 1, 0], device='cuda:0'),\n"," tensor([1, 0, 3, 3, 1, 3, 3, 3], device='cuda:0'),\n"," tensor([1, 3, 1, 2, 0, 3, 0, 0], device='cuda:0'),\n"," tensor([1, 0, 3, 3, 3, 2, 0, 2], device='cuda:0'),\n"," tensor([3, 2, 3, 0, 3, 0, 1, 2], device='cuda:0'),\n"," tensor([2, 3, 3, 0, 1, 3, 0, 0], device='cuda:0'),\n"," tensor([2, 2, 3, 3, 1, 0, 3, 3], device='cuda:0'),\n"," tensor([0, 3, 0, 0, 0, 0, 3, 2], device='cuda:0'),\n"," tensor([1, 1, 3, 1, 2, 3, 3, 0], device='cuda:0'),\n"," tensor([1, 1, 3, 3, 0, 0, 3, 1], device='cuda:0'),\n"," tensor([1, 0, 1, 1, 3, 1, 2, 1], device='cuda:0'),\n"," tensor([2, 0, 1, 1, 2, 0, 3, 3], device='cuda:0'),\n"," tensor([1, 3, 3, 0, 3, 2, 3, 1], device='cuda:0'),\n"," tensor([3, 3, 2, 0, 3, 3, 1, 3], device='cuda:0'),\n"," tensor([2, 3, 1, 0, 0, 2, 3, 1], device='cuda:0'),\n"," tensor([2, 3, 1, 3, 1, 3, 1, 1], device='cuda:0'),\n"," tensor([1, 1, 0, 2, 3, 3, 1, 0], device='cuda:0'),\n"," tensor([2, 3, 3, 1, 3, 1, 3, 2], device='cuda:0'),\n"," tensor([1, 2, 3, 0, 3, 1, 1, 2], device='cuda:0'),\n"," tensor([2, 1, 2, 2, 0, 1, 1, 3], device='cuda:0'),\n"," tensor([2, 2, 1, 0, 3, 2, 0, 0], device='cuda:0'),\n"," tensor([3, 0, 1, 1, 3, 0, 1, 2], device='cuda:0'),\n"," tensor([3, 2, 0, 2, 3, 2, 3, 0], device='cuda:0'),\n"," tensor([3, 3, 0, 1, 0, 0, 0, 0], device='cuda:0'),\n"," tensor([1, 0, 2, 0, 0, 3, 1, 1], device='cuda:0'),\n"," tensor([2, 2, 3, 2, 2, 3, 1, 0], device='cuda:0'),\n"," tensor([2, 2, 2, 0, 3, 2, 3, 1], device='cuda:0'),\n"," tensor([3, 3, 3, 3, 1, 0, 3, 3], device='cuda:0'),\n"," tensor([0, 0, 0, 3, 0, 1, 0, 2], device='cuda:0'),\n"," tensor([0, 2, 3, 1, 3, 3, 3, 0], device='cuda:0'),\n"," tensor([1, 0, 0, 2, 3, 0, 1, 1], device='cuda:0'),\n"," tensor([3, 2, 2, 1, 3, 3, 1, 1], device='cuda:0'),\n"," tensor([3, 1, 3, 2, 0, 2, 3, 2], device='cuda:0'),\n"," tensor([1, 0, 3, 3, 1, 1, 0, 0], device='cuda:0'),\n"," tensor([3, 3, 3, 3, 3, 3, 3, 0], device='cuda:0'),\n"," tensor([3, 1, 1, 0, 2, 0, 1, 0], device='cuda:0'),\n"," tensor([3, 0, 0, 1, 3, 3, 2, 0], device='cuda:0'),\n"," tensor([0, 0, 3, 0, 3, 3, 0, 1], device='cuda:0'),\n"," tensor([1, 0, 3, 2, 3, 0, 2, 1], device='cuda:0'),\n"," tensor([0, 1, 3, 0, 2, 0, 2, 0], device='cuda:0'),\n"," tensor([0, 2, 0, 2, 2, 1, 0, 0], device='cuda:0'),\n"," tensor([1, 3, 1, 0, 1, 3, 1, 2], device='cuda:0'),\n"," tensor([3, 0, 2, 1, 1, 1, 2, 3], device='cuda:0'),\n"," tensor([1, 3, 3, 0, 2, 0, 3, 1], device='cuda:0'),\n"," tensor([1, 0, 2, 2, 0, 3, 3, 0], device='cuda:0'),\n"," tensor([2, 1, 1, 2, 1, 1, 3, 3], device='cuda:0'),\n"," tensor([0, 2, 2, 3, 1, 3, 3, 1], device='cuda:0'),\n"," tensor([3, 3, 3, 1, 2, 2, 0, 2], device='cuda:0'),\n"," tensor([1, 0, 2, 3, 3, 3, 0, 2], device='cuda:0'),\n"," tensor([0, 0, 2, 0, 1, 1, 2, 3], device='cuda:0'),\n"," tensor([1, 3, 3, 2, 0, 2, 1, 1], device='cuda:0'),\n"," tensor([3, 3, 3, 0, 0, 2, 0, 3], device='cuda:0'),\n"," tensor([1, 3, 2, 2, 0, 3, 2, 2], device='cuda:0'),\n"," tensor([3, 0, 2, 2, 1, 1, 2, 2], device='cuda:0'),\n"," tensor([2, 0, 2, 1, 3, 3, 2, 2], device='cuda:0'),\n"," tensor([3, 1, 1, 0, 3, 2, 0, 3], device='cuda:0'),\n"," tensor([3, 0, 0, 1, 0, 3, 0, 1], device='cuda:0'),\n"," tensor([1, 2, 0, 2, 3, 2, 3, 0], device='cuda:0'),\n"," tensor([0, 1, 0, 1, 3, 1, 1, 1], device='cuda:0'),\n"," tensor([3, 2, 0, 3, 2, 3, 0, 1], device='cuda:0'),\n"," tensor([0, 3, 1, 2, 1, 1, 0, 0], device='cuda:0'),\n"," tensor([3, 2, 3, 1, 3, 2, 0, 3], device='cuda:0'),\n"," tensor([3, 2, 2, 3, 2, 3, 1, 0], device='cuda:0'),\n"," tensor([2, 2, 3, 2, 1, 0, 1, 1], device='cuda:0'),\n"," tensor([0, 0, 3, 3, 2, 0, 0, 2], device='cuda:0'),\n"," tensor([3, 2, 0, 3, 0, 0, 3, 2], device='cuda:0'),\n"," tensor([2, 2, 3, 3, 0, 2, 2, 0], device='cuda:0'),\n"," tensor([3, 2, 3, 3, 1, 3, 1, 3], device='cuda:0'),\n"," tensor([2, 1, 3, 2, 3, 2, 2, 3], device='cuda:0'),\n"," tensor([1, 1, 0, 0, 1, 0, 3, 2], device='cuda:0'),\n"," tensor([2, 0, 0, 2, 2, 0, 1, 1], device='cuda:0'),\n"," tensor([1, 1, 0, 0, 1, 1, 2, 3], device='cuda:0'),\n"," tensor([0, 3, 0, 0, 3, 3, 3, 2], device='cuda:0'),\n"," tensor([3, 3, 2, 3, 1, 3, 0, 0], device='cuda:0'),\n"," tensor([3, 2, 3, 0, 3, 3, 3, 3], device='cuda:0'),\n"," tensor([0, 1, 2, 3, 0, 3, 0, 2], device='cuda:0'),\n"," tensor([1, 2, 1, 3, 1, 1, 1, 0], device='cuda:0'),\n"," tensor([0, 2, 1, 2, 2, 2, 2, 0], device='cuda:0'),\n"," tensor([3, 2, 2, 1, 3, 3, 3, 1], device='cuda:0'),\n"," tensor([0, 3, 2, 2, 2, 2, 0, 3], device='cuda:0'),\n"," tensor([3, 3, 1, 0, 3, 2, 3, 0], device='cuda:0'),\n"," tensor([1, 0, 2, 0, 3, 3, 1, 1], device='cuda:0'),\n"," tensor([3, 3, 2, 2, 3, 1, 0, 1], device='cuda:0'),\n"," tensor([3, 3, 0, 3, 0, 0, 1, 2], device='cuda:0'),\n"," tensor([3, 2, 1, 2, 2, 0, 1, 3], device='cuda:0'),\n"," tensor([0, 3, 3, 2, 2, 1, 1, 0], device='cuda:0'),\n"," tensor([2, 1, 2, 0, 0, 3, 3, 0], device='cuda:0'),\n"," tensor([1, 0, 2, 1, 2, 0, 1, 1], device='cuda:0'),\n"," tensor([3, 3, 3, 1, 0, 0, 3, 1], device='cuda:0'),\n"," tensor([1, 1, 1, 1, 1, 1, 3, 2], device='cuda:0'),\n"," tensor([1, 2, 1, 3, 0, 1, 0, 0], device='cuda:0'),\n"," tensor([3, 0, 3, 0, 0, 0, 1, 1], device='cuda:0'),\n"," tensor([0, 0, 3, 0, 1, 1, 1, 2], device='cuda:0'),\n"," tensor([3, 2, 0, 3, 0, 3, 3, 3], device='cuda:0'),\n"," tensor([0, 3, 2, 1, 0, 0, 1, 0], device='cuda:0'),\n"," tensor([1, 2, 2, 3, 3, 2, 0, 3], device='cuda:0'),\n"," tensor([3, 1, 0, 2, 2, 3, 2, 3], device='cuda:0')]"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":[],"metadata":{"id":"ncjZ2pGIwNME"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bM7SN_mSKzYQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3GOOoTIUKzZk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dDNgf9ttKzbn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"eO0FH3g7KzcV"},"execution_count":null,"outputs":[]}]}