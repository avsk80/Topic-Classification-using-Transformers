{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1saviTKwy4DP0BLE1p1KoL7hTcYdX8QRh","timestamp":1683423728861}],"gpuType":"T4","mount_file_id":"16jDGKjraBfSGX5cDZavIQKCoaBQWyQpK","authorship_tag":"ABX9TyNI4txYTfQUjloShfzQepU4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"350b05cb2586483fba6266acc0eb8ce8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_31fbc720282844b6acfb3b5608e34b65","IPY_MODEL_dd0a2eb98ca64c258b12c232d4d29fc2","IPY_MODEL_5560c911b2aa453f95b444e2fcd97e0c"],"layout":"IPY_MODEL_8a09c70232b4447aa0d9f79239c19ddd"}},"31fbc720282844b6acfb3b5608e34b65":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55ad6596de4e4579b261bbe10fd3df28","placeholder":"​","style":"IPY_MODEL_48ef0794ee3d44f18341fb06924ef394","value":"Downloading (…)okenizer_config.json: 100%"}},"dd0a2eb98ca64c258b12c232d4d29fc2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b333689642f47798ef80074947b08b7","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8f746a25459141d48fded4aca6a8b3c5","value":28}},"5560c911b2aa453f95b444e2fcd97e0c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_147487d0897f470b947df3b4f810928d","placeholder":"​","style":"IPY_MODEL_5db7a9f2281d497d884b09dc6914a505","value":" 28.0/28.0 [00:00&lt;00:00, 1.18kB/s]"}},"8a09c70232b4447aa0d9f79239c19ddd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55ad6596de4e4579b261bbe10fd3df28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48ef0794ee3d44f18341fb06924ef394":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b333689642f47798ef80074947b08b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f746a25459141d48fded4aca6a8b3c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"147487d0897f470b947df3b4f810928d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5db7a9f2281d497d884b09dc6914a505":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c1f1237dcc2498d87aa31d8acbcde14":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d41a5411b1034b7ca86ccea3d0030ceb","IPY_MODEL_a5d823fc1bdc454ba50d1bc148907d2c","IPY_MODEL_ad0edea6d2fd4f13b24bbae1bd2a381d"],"layout":"IPY_MODEL_9f2c998bb518418185a606c301f06229"}},"d41a5411b1034b7ca86ccea3d0030ceb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18c151aab41545a0be6b1b58f2cdec6b","placeholder":"​","style":"IPY_MODEL_8f774c84b45149febeaf5262faa00d56","value":"Downloading (…)lve/main/config.json: 100%"}},"a5d823fc1bdc454ba50d1bc148907d2c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6173122b4aa146218fe8dfe6ed33f185","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_513052ea952a4220b78d94432d6329ca","value":570}},"ad0edea6d2fd4f13b24bbae1bd2a381d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b86c5e4ab281492794201fd5ba8c7afa","placeholder":"​","style":"IPY_MODEL_4b13100054c04658acd9dd1df49bd948","value":" 570/570 [00:00&lt;00:00, 29.8kB/s]"}},"9f2c998bb518418185a606c301f06229":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18c151aab41545a0be6b1b58f2cdec6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f774c84b45149febeaf5262faa00d56":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6173122b4aa146218fe8dfe6ed33f185":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"513052ea952a4220b78d94432d6329ca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b86c5e4ab281492794201fd5ba8c7afa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b13100054c04658acd9dd1df49bd948":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87b50f346dae45e3b30acf7cbc61ce27":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_530242314acd4cc3898fd23ea7b85f2d","IPY_MODEL_12488fdb94a4461a86ddb93ff50fb582","IPY_MODEL_7bc8a2e1d8924facba093b070f153647"],"layout":"IPY_MODEL_c96ea5e45bb84403b8d2b6f7d9824e99"}},"530242314acd4cc3898fd23ea7b85f2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff0dc6042214463cb768f897c2b9a151","placeholder":"​","style":"IPY_MODEL_d6a1a57faa474557a09c7a7aa06a5f39","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"12488fdb94a4461a86ddb93ff50fb582":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_86e4175bb1c74795b2fd14a4609448de","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f10b4994b7804110a8fe785db0d04b7c","value":231508}},"7bc8a2e1d8924facba093b070f153647":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb3e071503e6420cb43880fd81956748","placeholder":"​","style":"IPY_MODEL_88e983b0ea004d89a4c614ccbd719820","value":" 232k/232k [00:00&lt;00:00, 4.07MB/s]"}},"c96ea5e45bb84403b8d2b6f7d9824e99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff0dc6042214463cb768f897c2b9a151":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6a1a57faa474557a09c7a7aa06a5f39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86e4175bb1c74795b2fd14a4609448de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f10b4994b7804110a8fe785db0d04b7c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb3e071503e6420cb43880fd81956748":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88e983b0ea004d89a4c614ccbd719820":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d4e7594b8bb4f35afe1a0c3a8317212":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f9ac306f46544969315245f0d05a41d","IPY_MODEL_523f4f7aad7d472d953f465e2b81d5e5","IPY_MODEL_bb7ab08eb7d64f828d1947b97f87190e"],"layout":"IPY_MODEL_b32762be387d4ed0b1f466efc01e22dd"}},"2f9ac306f46544969315245f0d05a41d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96eb97bc3d374a75839805566212ed54","placeholder":"​","style":"IPY_MODEL_8c32b483fdbc47e987d92c4c0d20c0a8","value":"Downloading (…)/main/tokenizer.json: 100%"}},"523f4f7aad7d472d953f465e2b81d5e5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_77b7e02f165f492480d151e30b5541cb","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5ff151d070e34803b81cf574d65bb32d","value":466062}},"bb7ab08eb7d64f828d1947b97f87190e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01b09c7c682d476f98778815bbe72c25","placeholder":"​","style":"IPY_MODEL_cfc4fccbba214ecbb149e35dabcfdac2","value":" 466k/466k [00:00&lt;00:00, 16.5MB/s]"}},"b32762be387d4ed0b1f466efc01e22dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96eb97bc3d374a75839805566212ed54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c32b483fdbc47e987d92c4c0d20c0a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77b7e02f165f492480d151e30b5541cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ff151d070e34803b81cf574d65bb32d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"01b09c7c682d476f98778815bbe72c25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfc4fccbba214ecbb149e35dabcfdac2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"482aadfb82d54a9db0500f20d7ec2a83":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_58a991a09eef4d96bc6e75776b4940eb","IPY_MODEL_b4aa8b2800de4f869090798d791afc35","IPY_MODEL_710fdae9924c4408b8162fe759fd8c67"],"layout":"IPY_MODEL_8321a857798444d3ba435056f07ee9f7"}},"58a991a09eef4d96bc6e75776b4940eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1e707e774494745bad676e279002bb4","placeholder":"​","style":"IPY_MODEL_78ab3a3c6d1b4f72a25fc5dbeeecde9c","value":"Downloading pytorch_model.bin: 100%"}},"b4aa8b2800de4f869090798d791afc35":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_40b14f171dbe4b86b07681ab6cd99e8d","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a6fcc41ef944c6a9730695625ed120b","value":440473133}},"710fdae9924c4408b8162fe759fd8c67":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_407308ab05fc4c4d91f899a9bdef4a43","placeholder":"​","style":"IPY_MODEL_b313044f409c437e802114f505196df1","value":" 440M/440M [00:02&lt;00:00, 175MB/s]"}},"8321a857798444d3ba435056f07ee9f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1e707e774494745bad676e279002bb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78ab3a3c6d1b4f72a25fc5dbeeecde9c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40b14f171dbe4b86b07681ab6cd99e8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a6fcc41ef944c6a9730695625ed120b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"407308ab05fc4c4d91f899a9bdef4a43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b313044f409c437e802114f505196df1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y8EkIjvqKMbw","executionInfo":{"status":"ok","timestamp":1683699363334,"user_tz":300,"elapsed":37298,"user":{"displayName":"Venkata Sai Krishna Abbaraju","userId":"03956108207244612420"}},"outputId":"dc3309f9-89b7-456c-c438-c62bfff93655"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.11.0 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting shap\n","  Downloading shap-0.41.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (572 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.6/572.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.22.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.10.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)\n","Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.65.0)\n","Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.1)\n","Collecting slicer==0.0.7 (from shap)\n","  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.56.4)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.39.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->shap) (67.7.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2022.7.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.1.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n","Installing collected packages: slicer, shap\n","Successfully installed shap-0.41.0 slicer-0.0.7\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers_interpret\n","  Downloading transformers_interpret-0.10.0-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting captum>=0.3.1 (from transformers_interpret)\n","  Downloading captum-0.6.0-py3-none-any.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: ipython<8.0.0,>=7.31.1 in /usr/local/lib/python3.10/dist-packages (from transformers_interpret) (7.34.0)\n","Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from transformers_interpret) (4.28.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum>=0.3.1->transformers_interpret) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum>=0.3.1->transformers_interpret) (1.22.4)\n","Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum>=0.3.1->transformers_interpret) (2.0.0+cu118)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.31.1->transformers_interpret) (67.7.2)\n","Collecting jedi>=0.16 (from ipython<8.0.0,>=7.31.1->transformers_interpret)\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.31.1->transformers_interpret) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.31.1->transformers_interpret) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.31.1->transformers_interpret) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.31.1->transformers_interpret) (3.0.38)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.31.1->transformers_interpret) (2.14.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.31.1->transformers_interpret) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.31.1->transformers_interpret) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.31.1->transformers_interpret) (4.8.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->transformers_interpret) (3.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->transformers_interpret) (0.14.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->transformers_interpret) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->transformers_interpret) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->transformers_interpret) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->transformers_interpret) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->transformers_interpret) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->transformers_interpret) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=3.0.0->transformers_interpret) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=3.0.0->transformers_interpret) (4.5.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython<8.0.0,>=7.31.1->transformers_interpret) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython<8.0.0,>=7.31.1->transformers_interpret) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0.0,>=7.31.1->transformers_interpret) (0.2.6)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum>=0.3.1->transformers_interpret) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum>=0.3.1->transformers_interpret) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum>=0.3.1->transformers_interpret) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum>=0.3.1->transformers_interpret) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->captum>=0.3.1->transformers_interpret) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->captum>=0.3.1->transformers_interpret) (16.0.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum>=0.3.1->transformers_interpret) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum>=0.3.1->transformers_interpret) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum>=0.3.1->transformers_interpret) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum>=0.3.1->transformers_interpret) (1.4.4)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum>=0.3.1->transformers_interpret) (8.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum>=0.3.1->transformers_interpret) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum>=0.3.1->transformers_interpret) (2.8.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=3.0.0->transformers_interpret) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=3.0.0->transformers_interpret) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=3.0.0->transformers_interpret) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=3.0.0->transformers_interpret) (3.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum>=0.3.1->transformers_interpret) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum>=0.3.1->transformers_interpret) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum>=0.3.1->transformers_interpret) (1.3.0)\n","Installing collected packages: jedi, captum, transformers_interpret\n","Successfully installed captum-0.6.0 jedi-0.18.2 transformers_interpret-0.10.0\n"]}],"source":["!pip install transformers\n","!pip install shap\n","!pip install transformers_interpret\n","import transformers_interpret\n","import shap\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import transformers\n","import torch\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","source":["df = pd.read_csv(\"/content/drive/MyDrive/pro/8701/combined_14510_xlnet.csv\")\n","df.head()\n","title_content = df[(df['title_polyglot_detect'] == 'en') & (df['title_lang_detect'] == 'en') & (df['title_langid_detect'] == 'en') & (df['title_xl_detect'] == 'en') & (df['content_polyglot_detect'] == 'en') & (df['content_lang_detect'] == 'en') & (df['content_langid_detect'] == 'en') & (df['content_xl_detect'] == 'en')][['question_title', 'question_content', 'class_index']]\n","# title_content.shape\n","title_content['title_content'] = title_content['question_title'] + \" \" +title_content['question_content']"],"metadata":{"id":"Pofp17ngKa4d","executionInfo":{"status":"ok","timestamp":1683699365067,"user_tz":300,"elapsed":1737,"user":{"displayName":"Venkata Sai Krishna Abbaraju","userId":"03956108207244612420"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import transformers\n","from transformers import AutoModel, BertTokenizerFast\n","\n","# specify GPU\n","from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'"],"metadata":{"id":"NllVI1asKsKB","executionInfo":{"status":"ok","timestamp":1683699365067,"user_tz":300,"elapsed":149,"user":{"displayName":"Venkata Sai Krishna Abbaraju","userId":"03956108207244612420"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","label2id = {\n","    1: 0,\n","    5: 1,\n","    6: 2,\n","    10: 3\n","}\n","\n","id2label = {\n","    0: 1,\n","    1: 5,\n","    2: 6,\n","    3: 10\n","}\n","class Dataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, df):\n","\n","        self.labels = [label2id[label] for label in df['class_index']]\n","        self.texts = [tokenizer(text, add_special_tokens = True,\n","                               padding='max_length', max_length = 512, truncation=True,\n","                                return_tensors=\"pt\") for text in df['title_content']]\n","\n","    def classes(self):\n","        return self.labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def get_batch_labels(self, idx):\n","        # Fetch a batch of labels\n","        return np.array(self.labels[idx])\n","\n","    def get_batch_texts(self, idx):\n","        # Fetch a batch of inputs\n","        return self.texts[idx]\n","\n","    def __getitem__(self, idx):\n","\n","        batch_texts = self.get_batch_texts(idx)\n","        batch_y = self.get_batch_labels(idx)\n","\n","        return batch_texts, batch_y"],"metadata":{"id":"JTP1tiyKmehl","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["350b05cb2586483fba6266acc0eb8ce8","31fbc720282844b6acfb3b5608e34b65","dd0a2eb98ca64c258b12c232d4d29fc2","5560c911b2aa453f95b444e2fcd97e0c","8a09c70232b4447aa0d9f79239c19ddd","55ad6596de4e4579b261bbe10fd3df28","48ef0794ee3d44f18341fb06924ef394","2b333689642f47798ef80074947b08b7","8f746a25459141d48fded4aca6a8b3c5","147487d0897f470b947df3b4f810928d","5db7a9f2281d497d884b09dc6914a505","0c1f1237dcc2498d87aa31d8acbcde14","d41a5411b1034b7ca86ccea3d0030ceb","a5d823fc1bdc454ba50d1bc148907d2c","ad0edea6d2fd4f13b24bbae1bd2a381d","9f2c998bb518418185a606c301f06229","18c151aab41545a0be6b1b58f2cdec6b","8f774c84b45149febeaf5262faa00d56","6173122b4aa146218fe8dfe6ed33f185","513052ea952a4220b78d94432d6329ca","b86c5e4ab281492794201fd5ba8c7afa","4b13100054c04658acd9dd1df49bd948","87b50f346dae45e3b30acf7cbc61ce27","530242314acd4cc3898fd23ea7b85f2d","12488fdb94a4461a86ddb93ff50fb582","7bc8a2e1d8924facba093b070f153647","c96ea5e45bb84403b8d2b6f7d9824e99","ff0dc6042214463cb768f897c2b9a151","d6a1a57faa474557a09c7a7aa06a5f39","86e4175bb1c74795b2fd14a4609448de","f10b4994b7804110a8fe785db0d04b7c","bb3e071503e6420cb43880fd81956748","88e983b0ea004d89a4c614ccbd719820","8d4e7594b8bb4f35afe1a0c3a8317212","2f9ac306f46544969315245f0d05a41d","523f4f7aad7d472d953f465e2b81d5e5","bb7ab08eb7d64f828d1947b97f87190e","b32762be387d4ed0b1f466efc01e22dd","96eb97bc3d374a75839805566212ed54","8c32b483fdbc47e987d92c4c0d20c0a8","77b7e02f165f492480d151e30b5541cb","5ff151d070e34803b81cf574d65bb32d","01b09c7c682d476f98778815bbe72c25","cfc4fccbba214ecbb149e35dabcfdac2"]},"executionInfo":{"status":"ok","timestamp":1683699365104,"user_tz":300,"elapsed":186,"user":{"displayName":"Venkata Sai Krishna Abbaraju","userId":"03956108207244612420"}},"outputId":"8cbe9cf3-4809-4ee1-fec1-a9e595eaf4a0"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"350b05cb2586483fba6266acc0eb8ce8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c1f1237dcc2498d87aa31d8acbcde14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87b50f346dae45e3b30acf7cbc61ce27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d4e7594b8bb4f35afe1a0c3a8317212"}},"metadata":{}}]},{"cell_type":"code","source":["np.random.seed(112)\n","df_train, df_val, df_test = np.split(title_content.sample(frac=1, random_state=42), \n","                                     [int(.8*len(title_content)), int(.9*len(title_content))])\n","\n","print(len(df_train),len(df_val), len(df_test)) #dataframes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3liry60Bmedj","executionInfo":{"status":"ok","timestamp":1683699365104,"user_tz":300,"elapsed":3,"user":{"displayName":"Venkata Sai Krishna Abbaraju","userId":"03956108207244612420"}},"outputId":"973c8976-9178-4716-f847-8a040e7007cf"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["12026 1503 1504\n"]}]},{"cell_type":"code","source":["class BertClassifier(nn.Module):\n","\n","    def __init__(self):\n","        super(BertClassifier, self).__init__()\n","        self.bert = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 4, label2id=label2id, id2label=id2label)\n","        # self.linear = nn.Linear(768, 4)\n"," \n","    def forward(self, input_id, mask):\n","        pooled_output = self.bert(input_ids= input_id, attention_mask=mask)\n","        return pooled_output\n","\n","    def save_model(self, path, tokenizer): #'/content/drive/MyDrive/pro/8701/roberta_model_content/'\n","        self.bert.save_pretrained(path)\n","        tokenizer.save_pretrained(path)"],"metadata":{"id":"5SBgOaUFmecp","executionInfo":{"status":"ok","timestamp":1683699365105,"user_tz":300,"elapsed":3,"user":{"displayName":"Venkata Sai Krishna Abbaraju","userId":"03956108207244612420"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from torch.optim import Adam\n","from tqdm import tqdm\n","\n","def train(model, train_data, val_data, learning_rate, epochs):\n","\n","    train, val = Dataset(train_data), Dataset(val_data)\n","\n","    train_dataloader = torch.utils.data.DataLoader(train, batch_size=8, shuffle=True)\n","    val_dataloader = torch.utils.data.DataLoader(val, batch_size=8)\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = Adam(model.parameters(), lr= learning_rate)\n","\n","    train_acc = []\n","    valid_acc = []\n","\n","    if use_cuda:\n","\n","            model = model.cuda()\n","            criterion = criterion.cuda()\n","\n","    for epoch_num in range(epochs):\n","\n","            total_acc_train = 0\n","            total_loss_train = 0\n","\n","            for train_input, train_label in tqdm(train_dataloader):\n","\n","                train_label = train_label.to(device)\n","                mask = train_input['attention_mask'].to(device)\n","                input_id = train_input['input_ids'].squeeze(1).to(device)\n","\n","                output = model(input_id, mask)\n","                \n","                batch_loss = criterion(output.logits, train_label.long())\n","                total_loss_train += batch_loss.item()\n","                \n","                acc = (output.logits.argmax(dim=1) == train_label).sum().item()\n","                total_acc_train += acc\n","\n","                model.zero_grad()\n","                batch_loss.backward()\n","                optimizer.step()\n","            \n","            total_acc_val = 0\n","            total_loss_val = 0\n","\n","            with torch.no_grad():\n","\n","                for val_input, val_label in val_dataloader:\n","\n","                    val_label = val_label.to(device)\n","                    mask = val_input['attention_mask'].to(device)\n","                    input_id = val_input['input_ids'].squeeze(1).to(device)\n","\n","                    output = model(input_id, mask)\n","\n","                    batch_loss = criterion(output.logits, val_label.long())\n","                    total_loss_val += batch_loss.item()\n","                    \n","                    acc = (output.logits.argmax(dim=1) == val_label).sum().item()\n","                    total_acc_val += acc\n","            \n","            print(\n","                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n","                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n","                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n","                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n","            \n","            train_acc.append(total_acc_train / len(train_data))\n","            valid_acc.append(total_acc_val / len(val_data))\n","            \n","            path = '/content/drive/MyDrive/pro/8701/bert_model_content/saved_weights_' + str(epoch_num)\n","            print(path)\n","            # torch.save(model.state_dict(), path)\n","            model.save_model(path = path, tokenizer=tokenizer)\n","            \n","    return train_acc, valid_acc           \n","                  \n","EPOCHS = 3\n","model = BertClassifier()\n","LR = 1e-5\n","\n","train(model, df_train, df_val, LR, EPOCHS)\n","# train(model, df_train.iloc[:10], df_val.iloc[:8], LR, EPOCHS)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347,"referenced_widgets":["482aadfb82d54a9db0500f20d7ec2a83","58a991a09eef4d96bc6e75776b4940eb","b4aa8b2800de4f869090798d791afc35","710fdae9924c4408b8162fe759fd8c67","8321a857798444d3ba435056f07ee9f7","f1e707e774494745bad676e279002bb4","78ab3a3c6d1b4f72a25fc5dbeeecde9c","40b14f171dbe4b86b07681ab6cd99e8d","2a6fcc41ef944c6a9730695625ed120b","407308ab05fc4c4d91f899a9bdef4a43","b313044f409c437e802114f505196df1"]},"id":"1hJYylPboOTv","executionInfo":{"status":"ok","timestamp":1683702677491,"user_tz":300,"elapsed":3312389,"user":{"displayName":"Venkata Sai Krishna Abbaraju","userId":"03956108207244612420"}},"outputId":"3ec9ea8d-9e11-4b4e-fb76-89824bf59a38"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"482aadfb82d54a9db0500f20d7ec2a83"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100%|██████████| 1504/1504 [17:14<00:00,  1.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.042                 | Train Accuracy:  0.893                 | Val Loss:  0.038                 | Val Accuracy:  0.901\n","/content/drive/MyDrive/pro/8701/bert_model_content/saved_weights_0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1504/1504 [17:21<00:00,  1.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.017                 | Train Accuracy:  0.959                 | Val Loss:  0.035                 | Val Accuracy:  0.911\n","/content/drive/MyDrive/pro/8701/bert_model_content/saved_weights_1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1504/1504 [17:21<00:00,  1.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.007                 | Train Accuracy:  0.985                 | Val Loss:  0.043                 | Val Accuracy:  0.906\n","/content/drive/MyDrive/pro/8701/bert_model_content/saved_weights_2\n"]},{"output_type":"execute_result","data":{"text/plain":["([0.8928987194412107, 0.9590054881090969, 0.9852818892399801],\n"," [0.9008649367930806, 0.9108449767132402, 0.906187624750499])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":[],"metadata":{"id":"PEiehnoXb0NU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Run Till the above step. \n","Share the notebook, model weights that are saved and optimal parameters like epochs, LR. The notebook should have training and  validation error details."],"metadata":{"id":"ZAc16BajgKJV"}},{"cell_type":"code","source":["def evaluate(model, test_data):\n","\n","    test = Dataset(test_data)\n","    pred_label = []\n","    test_dataloader = torch.utils.data.DataLoader(test, batch_size=8)\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    if use_cuda:\n","\n","        model = model.cuda()\n","\n","    total_acc_test = 0\n","    with torch.no_grad():\n","\n","        for test_input, test_label in test_dataloader:\n","\n","              test_label = test_label.to(device)\n","              mask = test_input['attention_mask'].to(device)\n","              input_id = test_input['input_ids'].squeeze(1).to(device)\n","\n","              output = model(input_id, mask)\n","              pred = output.logits.argmax(dim=1)\n","              # print(pred)\n","              # print(test_label)\n","              pred_label.append(pred)\n","              acc = (output.logits.argmax(dim=1) == test_label).sum().item()\n","              total_acc_test += acc\n","    \n","    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n","    return pred_label\n","\n","#load weights of best model\n","model2 = AutoModelForSequenceClassification.from_pretrained('/content/drive/MyDrive/pro/8701/bert_model_content/saved_weights_1')\n","tokenizer2 = AutoTokenizer.from_pretrained('/content/drive/MyDrive/pro/8701/bert_model_content/saved_weights_1')\n","\n","evaluate(model2, df_test)\n","# evaluate(model_test, df_train.iloc[:10])\n","\n","#load weights of best model\n","# model_test = BertClassifier()\n","# path = '/content/drive/MyDrive/pro/8701/bert_model/saved_weights.pt'\n","# model_test.load_state_dict(torch.load(path))\n","\n","# evaluate(model_test, df_test)\n","# evaluate(model_test, df_train.iloc[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gDlWSuRBoeuO","executionInfo":{"status":"ok","timestamp":1683702739986,"user_tz":300,"elapsed":48978,"user":{"displayName":"Venkata Sai Krishna Abbaraju","userId":"03956108207244612420"}},"outputId":"478397b5-730e-46ee-b3bf-131af8badd17"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy:  0.930\n"]},{"output_type":"execute_result","data":{"text/plain":["[tensor([0, 2, 2, 0, 2, 2, 3, 2], device='cuda:0'),\n"," tensor([2, 3, 0, 3, 1, 2, 0, 1], device='cuda:0'),\n"," tensor([1, 1, 2, 0, 0, 1, 1, 2], device='cuda:0'),\n"," tensor([3, 3, 0, 1, 1, 3, 2, 0], device='cuda:0'),\n"," tensor([3, 3, 3, 3, 2, 1, 0, 0], device='cuda:0'),\n"," tensor([1, 0, 0, 0, 2, 1, 0, 0], device='cuda:0'),\n"," tensor([0, 1, 2, 3, 3, 0, 3, 2], device='cuda:0'),\n"," tensor([1, 1, 2, 0, 3, 3, 1, 3], device='cuda:0'),\n"," tensor([3, 0, 1, 3, 1, 3, 0, 1], device='cuda:0'),\n"," tensor([1, 0, 1, 2, 0, 1, 1, 0], device='cuda:0'),\n"," tensor([0, 3, 2, 1, 2, 2, 3, 2], device='cuda:0'),\n"," tensor([3, 0, 1, 0, 2, 3, 0, 0], device='cuda:0'),\n"," tensor([3, 0, 0, 0, 1, 2, 0, 3], device='cuda:0'),\n"," tensor([3, 2, 2, 3, 3, 1, 2, 1], device='cuda:0'),\n"," tensor([0, 3, 2, 0, 1, 3, 0, 1], device='cuda:0'),\n"," tensor([1, 0, 1, 0, 3, 0, 1, 1], device='cuda:0'),\n"," tensor([1, 3, 0, 1, 3, 3, 1, 0], device='cuda:0'),\n"," tensor([1, 3, 0, 0, 1, 3, 1, 0], device='cuda:0'),\n"," tensor([2, 0, 3, 2, 1, 0, 0, 0], device='cuda:0'),\n"," tensor([1, 0, 3, 3, 3, 3, 3, 2], device='cuda:0'),\n"," tensor([3, 2, 2, 1, 1, 1, 1, 0], device='cuda:0'),\n"," tensor([0, 0, 3, 1, 3, 0, 3, 0], device='cuda:0'),\n"," tensor([3, 1, 2, 3, 1, 1, 2, 1], device='cuda:0'),\n"," tensor([3, 3, 2, 1, 0, 3, 0, 1], device='cuda:0'),\n"," tensor([1, 0, 3, 0, 1, 1, 2, 2], device='cuda:0'),\n"," tensor([0, 2, 0, 1, 1, 2, 0, 2], device='cuda:0'),\n"," tensor([1, 0, 0, 2, 1, 0, 1, 1], device='cuda:0'),\n"," tensor([0, 3, 0, 2, 0, 1, 3, 0], device='cuda:0'),\n"," tensor([2, 1, 1, 1, 0, 0, 3, 3], device='cuda:0'),\n"," tensor([0, 0, 1, 2, 2, 3, 2, 2], device='cuda:0'),\n"," tensor([3, 3, 2, 0, 1, 1, 1, 2], device='cuda:0'),\n"," tensor([0, 2, 2, 2, 1, 0, 3, 3], device='cuda:0'),\n"," tensor([2, 0, 1, 0, 1, 3, 1, 1], device='cuda:0'),\n"," tensor([1, 3, 0, 3, 1, 1, 3, 0], device='cuda:0'),\n"," tensor([0, 1, 2, 1, 1, 0, 1, 0], device='cuda:0'),\n"," tensor([3, 1, 1, 3, 3, 0, 0, 1], device='cuda:0'),\n"," tensor([2, 2, 1, 2, 0, 2, 1, 1], device='cuda:0'),\n"," tensor([2, 0, 3, 0, 2, 2, 0, 3], device='cuda:0'),\n"," tensor([3, 2, 1, 2, 1, 3, 3, 1], device='cuda:0'),\n"," tensor([1, 1, 0, 1, 3, 1, 3, 1], device='cuda:0'),\n"," tensor([0, 3, 3, 0, 3, 3, 2, 0], device='cuda:0'),\n"," tensor([0, 2, 2, 1, 2, 3, 1, 2], device='cuda:0'),\n"," tensor([0, 2, 3, 2, 0, 0, 1, 0], device='cuda:0'),\n"," tensor([3, 3, 0, 0, 0, 3, 3, 2], device='cuda:0'),\n"," tensor([2, 0, 3, 3, 1, 0, 1, 2], device='cuda:0'),\n"," tensor([2, 1, 2, 0, 0, 0, 1, 3], device='cuda:0'),\n"," tensor([0, 2, 1, 2, 2, 3, 0, 3], device='cuda:0'),\n"," tensor([0, 2, 3, 2, 1, 1, 3, 2], device='cuda:0'),\n"," tensor([1, 3, 3, 1, 2, 1, 0, 1], device='cuda:0'),\n"," tensor([0, 0, 3, 3, 2, 3, 3, 2], device='cuda:0'),\n"," tensor([2, 3, 2, 1, 3, 1, 3, 2], device='cuda:0'),\n"," tensor([1, 0, 3, 0, 0, 0, 1, 1], device='cuda:0'),\n"," tensor([1, 1, 2, 1, 3, 3, 2, 3], device='cuda:0'),\n"," tensor([0, 1, 3, 0, 3, 0, 2, 2], device='cuda:0'),\n"," tensor([0, 0, 0, 3, 3, 1, 1, 3], device='cuda:0'),\n"," tensor([1, 3, 0, 0, 3, 0, 3, 0], device='cuda:0'),\n"," tensor([3, 3, 0, 1, 3, 0, 3, 3], device='cuda:0'),\n"," tensor([3, 2, 3, 0, 2, 0, 1, 2], device='cuda:0'),\n"," tensor([1, 3, 1, 3, 1, 3, 1, 2], device='cuda:0'),\n"," tensor([3, 2, 1, 3, 1, 3, 2, 3], device='cuda:0'),\n"," tensor([0, 1, 0, 3, 3, 3, 1, 0], device='cuda:0'),\n"," tensor([3, 1, 1, 1, 0, 1, 3, 2], device='cuda:0'),\n"," tensor([0, 1, 2, 1, 0, 1, 3, 0], device='cuda:0'),\n"," tensor([1, 1, 2, 0, 3, 3, 1, 0], device='cuda:0'),\n"," tensor([2, 2, 0, 3, 3, 3, 2, 3], device='cuda:0'),\n"," tensor([3, 1, 2, 3, 3, 0, 3, 1], device='cuda:0'),\n"," tensor([1, 0, 2, 2, 1, 0, 0, 2], device='cuda:0'),\n"," tensor([2, 1, 0, 2, 2, 3, 2, 0], device='cuda:0'),\n"," tensor([3, 2, 3, 3, 2, 2, 1, 0], device='cuda:0'),\n"," tensor([1, 2, 1, 0, 3, 2, 3, 3], device='cuda:0'),\n"," tensor([1, 0, 0, 1, 0, 3, 0, 3], device='cuda:0'),\n"," tensor([3, 2, 0, 3, 0, 1, 0, 0], device='cuda:0'),\n"," tensor([1, 3, 3, 2, 0, 3, 3, 3], device='cuda:0'),\n"," tensor([0, 3, 2, 3, 1, 0, 3, 3], device='cuda:0'),\n"," tensor([0, 2, 3, 2, 1, 2, 3, 0], device='cuda:0'),\n"," tensor([3, 1, 1, 3, 1, 1, 0, 2], device='cuda:0'),\n"," tensor([3, 2, 1, 0, 0, 1, 2, 1], device='cuda:0'),\n"," tensor([0, 2, 2, 3, 1, 3, 1, 2], device='cuda:0'),\n"," tensor([2, 2, 1, 2, 3, 1, 3, 1], device='cuda:0'),\n"," tensor([1, 3, 2, 3, 0, 3, 2, 2], device='cuda:0'),\n"," tensor([3, 3, 2, 3, 0, 0, 3, 2], device='cuda:0'),\n"," tensor([0, 0, 0, 2, 1, 0, 0, 1], device='cuda:0'),\n"," tensor([0, 0, 2, 1, 3, 2, 1, 0], device='cuda:0'),\n"," tensor([2, 3, 3, 3, 2, 2, 2, 2], device='cuda:0'),\n"," tensor([1, 3, 1, 3, 0, 3, 0, 0], device='cuda:0'),\n"," tensor([3, 0, 1, 1, 0, 3, 3, 1], device='cuda:0'),\n"," tensor([1, 1, 2, 1, 1, 2, 0, 1], device='cuda:0'),\n"," tensor([3, 1, 3, 0, 1, 0, 2, 1], device='cuda:0'),\n"," tensor([2, 3, 0, 2, 3, 0, 1, 1], device='cuda:0'),\n"," tensor([3, 0, 0, 3, 3, 0, 3, 1], device='cuda:0'),\n"," tensor([3, 1, 3, 3, 1, 3, 1, 3], device='cuda:0'),\n"," tensor([1, 3, 3, 3, 0, 0, 1, 0], device='cuda:0'),\n"," tensor([1, 0, 3, 3, 1, 3, 3, 3], device='cuda:0'),\n"," tensor([1, 3, 1, 2, 0, 0, 0, 0], device='cuda:0'),\n"," tensor([1, 0, 3, 3, 0, 2, 0, 2], device='cuda:0'),\n"," tensor([3, 2, 3, 0, 2, 0, 1, 2], device='cuda:0'),\n"," tensor([2, 3, 3, 0, 1, 0, 0, 0], device='cuda:0'),\n"," tensor([2, 2, 3, 3, 1, 0, 3, 3], device='cuda:0'),\n"," tensor([0, 3, 0, 0, 0, 0, 3, 2], device='cuda:0'),\n"," tensor([1, 1, 3, 1, 2, 3, 3, 0], device='cuda:0'),\n"," tensor([1, 1, 3, 3, 0, 0, 3, 1], device='cuda:0'),\n"," tensor([1, 0, 1, 1, 3, 1, 2, 1], device='cuda:0'),\n"," tensor([2, 0, 1, 1, 2, 0, 3, 3], device='cuda:0'),\n"," tensor([1, 3, 3, 0, 3, 2, 3, 1], device='cuda:0'),\n"," tensor([3, 3, 0, 0, 0, 3, 1, 0], device='cuda:0'),\n"," tensor([2, 3, 1, 0, 0, 2, 3, 1], device='cuda:0'),\n"," tensor([2, 3, 1, 3, 1, 2, 1, 1], device='cuda:0'),\n"," tensor([1, 1, 0, 2, 3, 3, 1, 0], device='cuda:0'),\n"," tensor([2, 3, 3, 1, 3, 1, 3, 2], device='cuda:0'),\n"," tensor([1, 2, 3, 0, 3, 1, 1, 2], device='cuda:0'),\n"," tensor([2, 1, 2, 2, 0, 1, 1, 3], device='cuda:0'),\n"," tensor([2, 2, 1, 0, 3, 2, 0, 0], device='cuda:0'),\n"," tensor([3, 0, 1, 1, 3, 0, 1, 2], device='cuda:0'),\n"," tensor([3, 2, 0, 2, 3, 2, 0, 0], device='cuda:0'),\n"," tensor([3, 3, 2, 1, 0, 0, 0, 0], device='cuda:0'),\n"," tensor([1, 0, 2, 0, 0, 3, 1, 1], device='cuda:0'),\n"," tensor([2, 2, 3, 2, 2, 0, 1, 1], device='cuda:0'),\n"," tensor([2, 2, 2, 0, 3, 2, 3, 1], device='cuda:0'),\n"," tensor([3, 3, 3, 3, 1, 0, 3, 3], device='cuda:0'),\n"," tensor([0, 0, 0, 3, 0, 1, 0, 2], device='cuda:0'),\n"," tensor([0, 2, 3, 1, 3, 3, 3, 0], device='cuda:0'),\n"," tensor([1, 0, 0, 2, 3, 0, 1, 1], device='cuda:0'),\n"," tensor([3, 2, 2, 1, 3, 3, 1, 1], device='cuda:0'),\n"," tensor([3, 1, 3, 2, 0, 2, 3, 2], device='cuda:0'),\n"," tensor([1, 0, 3, 3, 1, 1, 2, 0], device='cuda:0'),\n"," tensor([3, 3, 0, 3, 3, 3, 3, 2], device='cuda:0'),\n"," tensor([3, 1, 1, 0, 2, 0, 1, 0], device='cuda:0'),\n"," tensor([3, 0, 0, 1, 3, 3, 2, 0], device='cuda:0'),\n"," tensor([0, 0, 3, 0, 3, 3, 0, 1], device='cuda:0'),\n"," tensor([1, 0, 3, 2, 3, 0, 3, 1], device='cuda:0'),\n"," tensor([0, 1, 3, 0, 2, 0, 2, 0], device='cuda:0'),\n"," tensor([0, 2, 0, 2, 2, 1, 0, 0], device='cuda:0'),\n"," tensor([1, 3, 1, 0, 1, 3, 1, 2], device='cuda:0'),\n"," tensor([3, 3, 2, 1, 1, 1, 2, 3], device='cuda:0'),\n"," tensor([1, 3, 3, 0, 2, 0, 3, 1], device='cuda:0'),\n"," tensor([1, 0, 2, 2, 0, 3, 3, 0], device='cuda:0'),\n"," tensor([2, 1, 1, 2, 1, 1, 3, 1], device='cuda:0'),\n"," tensor([0, 2, 2, 3, 1, 3, 3, 1], device='cuda:0'),\n"," tensor([3, 3, 3, 1, 2, 2, 0, 2], device='cuda:0'),\n"," tensor([1, 0, 0, 3, 3, 2, 0, 2], device='cuda:0'),\n"," tensor([0, 0, 2, 0, 1, 1, 2, 3], device='cuda:0'),\n"," tensor([1, 3, 3, 2, 0, 2, 1, 1], device='cuda:0'),\n"," tensor([3, 3, 3, 0, 0, 2, 0, 3], device='cuda:0'),\n"," tensor([1, 3, 2, 2, 0, 3, 2, 2], device='cuda:0'),\n"," tensor([3, 0, 2, 2, 1, 1, 0, 2], device='cuda:0'),\n"," tensor([2, 0, 2, 1, 3, 3, 2, 2], device='cuda:0'),\n"," tensor([3, 1, 1, 0, 3, 2, 0, 3], device='cuda:0'),\n"," tensor([3, 0, 0, 1, 0, 3, 0, 1], device='cuda:0'),\n"," tensor([1, 2, 0, 2, 3, 2, 3, 0], device='cuda:0'),\n"," tensor([0, 1, 0, 1, 3, 1, 1, 1], device='cuda:0'),\n"," tensor([3, 2, 0, 3, 2, 3, 0, 1], device='cuda:0'),\n"," tensor([0, 3, 1, 2, 3, 1, 0, 0], device='cuda:0'),\n"," tensor([0, 2, 3, 1, 3, 0, 0, 3], device='cuda:0'),\n"," tensor([3, 2, 2, 3, 2, 3, 1, 0], device='cuda:0'),\n"," tensor([2, 2, 1, 2, 1, 0, 1, 1], device='cuda:0'),\n"," tensor([0, 0, 3, 3, 2, 0, 0, 2], device='cuda:0'),\n"," tensor([3, 2, 0, 3, 0, 0, 3, 2], device='cuda:0'),\n"," tensor([2, 2, 1, 3, 0, 2, 2, 0], device='cuda:0'),\n"," tensor([3, 2, 3, 3, 1, 3, 1, 3], device='cuda:0'),\n"," tensor([2, 1, 0, 2, 0, 2, 2, 3], device='cuda:0'),\n"," tensor([1, 1, 0, 0, 1, 0, 3, 2], device='cuda:0'),\n"," tensor([2, 0, 0, 2, 2, 0, 1, 1], device='cuda:0'),\n"," tensor([1, 1, 0, 0, 1, 1, 2, 3], device='cuda:0'),\n"," tensor([0, 3, 0, 0, 3, 3, 3, 2], device='cuda:0'),\n"," tensor([0, 3, 2, 3, 1, 3, 0, 0], device='cuda:0'),\n"," tensor([3, 2, 3, 0, 3, 3, 3, 3], device='cuda:0'),\n"," tensor([0, 1, 2, 3, 0, 3, 0, 2], device='cuda:0'),\n"," tensor([1, 2, 1, 3, 1, 1, 1, 2], device='cuda:0'),\n"," tensor([0, 2, 1, 2, 2, 2, 2, 0], device='cuda:0'),\n"," tensor([3, 2, 2, 1, 3, 3, 3, 1], device='cuda:0'),\n"," tensor([0, 0, 2, 2, 2, 2, 0, 3], device='cuda:0'),\n"," tensor([3, 3, 1, 0, 3, 2, 3, 0], device='cuda:0'),\n"," tensor([1, 0, 2, 0, 3, 3, 1, 1], device='cuda:0'),\n"," tensor([3, 3, 2, 2, 3, 1, 0, 1], device='cuda:0'),\n"," tensor([3, 3, 0, 3, 2, 0, 1, 2], device='cuda:0'),\n"," tensor([3, 2, 1, 2, 2, 0, 1, 3], device='cuda:0'),\n"," tensor([0, 3, 3, 2, 2, 1, 1, 0], device='cuda:0'),\n"," tensor([2, 1, 2, 0, 0, 3, 3, 0], device='cuda:0'),\n"," tensor([1, 0, 2, 1, 2, 0, 1, 1], device='cuda:0'),\n"," tensor([3, 3, 3, 1, 3, 0, 3, 1], device='cuda:0'),\n"," tensor([1, 1, 1, 1, 1, 1, 3, 2], device='cuda:0'),\n"," tensor([1, 2, 1, 3, 0, 1, 0, 0], device='cuda:0'),\n"," tensor([3, 0, 3, 0, 0, 0, 1, 1], device='cuda:0'),\n"," tensor([0, 0, 3, 0, 1, 1, 1, 2], device='cuda:0'),\n"," tensor([3, 2, 0, 3, 0, 3, 3, 3], device='cuda:0'),\n"," tensor([0, 3, 2, 1, 0, 0, 1, 0], device='cuda:0'),\n"," tensor([1, 2, 2, 3, 0, 2, 0, 3], device='cuda:0'),\n"," tensor([0, 1, 0, 3, 2, 3, 0, 3], device='cuda:0')]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":[],"metadata":{"id":"ncjZ2pGIwNME"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bM7SN_mSKzYQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3GOOoTIUKzZk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dDNgf9ttKzbn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"eO0FH3g7KzcV"},"execution_count":null,"outputs":[]}]}